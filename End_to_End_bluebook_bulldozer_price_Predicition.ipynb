{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "End-to-End-bluebook-bulldozer-price-Predicition.ipynb",
      "provenance": [],
      "mount_file_id": "1frsF7koURdjoTzhuCB4275t-QrNkbOx0",
      "authorship_tag": "ABX9TyOGcxU9qVWZ4SUOFsHNjoqE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymanaboghonim/My_Projects/blob/main/End_to_End_bluebook_bulldozer_price_Predicition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC-JCsEofVO0"
      },
      "source": [
        "# <font color='red'>Problem Definition & Formulation</font>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LuGZchCfdDA"
      },
      "source": [
        "The problem formulation phase of the ML Pipeline is critical, and it’s where everything begins.It starts by seeing a problem and thinking “what question, if I could answer it, would provide the most value to my business?” \r\n",
        "\r\n",
        "Part of the problem formulation phase includes seeing where there are opportunities to use machine learning and consider the following questions:\r\n",
        "1.\tIs machine learning appropriate for this problem, and why or why not?\r\n",
        "2.\tWhat is the ML problem if there is one, and what would a success metric look like?\r\n",
        "3.\tWhat kind of ML problem is this?\r\n",
        "4.\tIs the data appropriate?\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8-ys83PfiLM"
      },
      "source": [
        "# Answers for the four mentioned questions!\r\n",
        "To answer those question, I must understand the problem well and then explore the data to build and inution about it, then come up with rigoures arguments which lead to a conclusion and prespictives. \r\n",
        "\r\n",
        "1)\tML is appropriate because of the scale and Variety of the Data . There are potentially High diemensional Features and about of half million of the Training examples which  makes the problem to be very difficult for Human to be solved without the use of ML. In addition, ML solution will offer a scalable and reusable solution for the problem.\r\n",
        "\r\n",
        "2)\tThe problem is :How well can we predict the future sale price of a bulldozer, given its characteristics and previous examples of how much similar bulldozers have been sold for?\r\n",
        "i.\tSuccess would be the minimum root mean squared log error (RMSLE) because it is a Kaggle competition and  Kaggle has set this evaluation metric to being used.\r\n",
        "\r\n",
        "3)\tThis is a supervised Regression ML problem because we have a labeled data point and the output is a Numerical value.\r\n",
        "\r\n",
        "4)\tThis data is appropriate because it has variety of historical data of similar products and The characteristics of the Bulldozer,  and there are a lot of examples with  labeled target to train, tune and test the model .\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJPFPZg6jjwX"
      },
      "source": [
        "# <font color='blue'>Importing Libraries and Modules </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnwzEF0mfb5p"
      },
      "source": [
        "# Import data analysis tools \r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from pandas_profiling import ProfileReport\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "\r\n",
        "# import model modules\r\n",
        "from sklearn.neighbors import KNeighborsRegressor\r\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "\r\n",
        "# import model evaluation modules\r\n",
        "from sklearn.metrics import mean_squared_log_error #because kaggle want this metric\r\n",
        "\r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1Lsz1VXrWY6"
      },
      "source": [
        "# <font color='blue'>Loading Data </font>\r\n",
        "\r\n",
        "There are 3 datasets:\r\n",
        "\r\n",
        "* Train.csv - Historical bulldozer sales examples up to 2011 (close to 400,000 examples with 50+ different attributes, including SalePrice which is the target variable).\r\n",
        "* Valid.csv - Historical bulldozer sales examples from January 1 2012 to April 30 2012 (close to 12,000 examples with the same attributes as Train.csv).\r\n",
        "* Test.csv - Historical bulldozer sales examples from May 1 2012 to November 2012 (close to 12,000 examples but missing the SalePrice attribute, as this is what we'll be trying to predict).\r\n",
        "\r\n",
        "## Features\r\n",
        "\r\n",
        "\r\n",
        "For this dataset, Kaggle provide a data dictionary which contains information about what each attribute of the dataset means. You can download this file directly from the Kaggle competition page  [here](https://www.kaggle.com/c/bluebook-for-bulldozers/download/Bnl6RAHA0enbg0UfAvGA%2Fversions%2FwBG4f35Q8mAbfkzwCeZn%2Ffiles%2FData%20Dictionary.xlsx) (account required) or view it on Google Sheets.\r\n",
        "\r\n",
        "With all of this being known, let's get started!\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrXZt8NHrCJi",
        "outputId": "d5c6a728-3985-4330-af9b-248da51f65ec"
      },
      "source": [
        "# Import the training and validation set\r\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/TrainAndValid.csv\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (13,39,40,41) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-j0R0ctvnKb"
      },
      "source": [
        "# <font color='red'>  EDA & Data Preparation </font>\r\n",
        "\r\n",
        "# EDA is crucial step that help us explore and understand our data to build an intution  about it, and outline the required preprocessing steps before the modeling stage. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4bv-b17fWEd"
      },
      "source": [
        "## * In this new version, I will use Pandas profiling as an automated EDA technique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quLpCvhNqMpj"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLkgfVRGf5TA"
      },
      "source": [
        "# Automated_EDA_Report = ProfileReport (df)\r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGz8WZF1qnbz"
      },
      "source": [
        "# Automated_EDA_Report.to_notebook_iframe()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaLVdxY9tPkG"
      },
      "source": [
        "# Lets start with an overview of our data\r\n",
        "# df.head(10)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTC1qMP1wEA1"
      },
      "source": [
        "#Lets identify our features(Columns) names, counts and datatypes\r\n",
        "#df.info()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Da7W5BAQYb"
      },
      "source": [
        "### It is clear that we have combination of numerical and categorical data, and we have missed data because the count of features is not the same for each features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbDKFK1o-1fn"
      },
      "source": [
        "#Lets check the missing values  \r\n",
        "#df.isna().sum()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqq-BDSkA1Jd"
      },
      "source": [
        "### There are some features without missing data, some with accepted small amount of missing data that can be imputed, and others with very large missing data that we can not deal with and we will drop them later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR9y1Iic_SQR"
      },
      "source": [
        "#Check the distribution of the SalePrice using histogram\r\n",
        "#df.SalePrice.plot.hist()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYpjy-PyDPbh"
      },
      "source": [
        "# Check some statistics about SalePrice\r\n",
        "#df[\"SalePrice\"].describe()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5FlhLyeHPwt"
      },
      "source": [
        "## Parsing dates\r\n",
        "When working with time series data, it's a good idea to make sure any date data is the format of a [datetime object](https://docs.python.org/3/library/datetime.html) (a Python data type which encodes specific information about dates).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZqiJAmaERJD"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/TrainAndValid.csv\",\r\n",
        "                 low_memory=False,\r\n",
        "                 parse_dates=[\"saledate\"])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz_Pfs7_E2Oe",
        "outputId": "6d79d4bd-cbc5-4e8c-c9ed-1c32085b0500"
      },
      "source": [
        "# check the datatype of saledate after parsing\r\n",
        "df.info()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 412698 entries, 0 to 412697\n",
            "Data columns (total 53 columns):\n",
            " #   Column                    Non-Null Count   Dtype         \n",
            "---  ------                    --------------   -----         \n",
            " 0   SalesID                   412698 non-null  int64         \n",
            " 1   SalePrice                 412698 non-null  float64       \n",
            " 2   MachineID                 412698 non-null  int64         \n",
            " 3   ModelID                   412698 non-null  int64         \n",
            " 4   datasource                412698 non-null  int64         \n",
            " 5   auctioneerID              392562 non-null  float64       \n",
            " 6   YearMade                  412698 non-null  int64         \n",
            " 7   MachineHoursCurrentMeter  147504 non-null  float64       \n",
            " 8   UsageBand                 73670 non-null   object        \n",
            " 9   saledate                  412698 non-null  datetime64[ns]\n",
            " 10  fiModelDesc               412698 non-null  object        \n",
            " 11  fiBaseModel               412698 non-null  object        \n",
            " 12  fiSecondaryDesc           271971 non-null  object        \n",
            " 13  fiModelSeries             58667 non-null   object        \n",
            " 14  fiModelDescriptor         74816 non-null   object        \n",
            " 15  ProductSize               196093 non-null  object        \n",
            " 16  fiProductClassDesc        412698 non-null  object        \n",
            " 17  state                     412698 non-null  object        \n",
            " 18  ProductGroup              412698 non-null  object        \n",
            " 19  ProductGroupDesc          412698 non-null  object        \n",
            " 20  Drive_System              107087 non-null  object        \n",
            " 21  Enclosure                 412364 non-null  object        \n",
            " 22  Forks                     197715 non-null  object        \n",
            " 23  Pad_Type                  81096 non-null   object        \n",
            " 24  Ride_Control              152728 non-null  object        \n",
            " 25  Stick                     81096 non-null   object        \n",
            " 26  Transmission              188007 non-null  object        \n",
            " 27  Turbocharged              81096 non-null   object        \n",
            " 28  Blade_Extension           25983 non-null   object        \n",
            " 29  Blade_Width               25983 non-null   object        \n",
            " 30  Enclosure_Type            25983 non-null   object        \n",
            " 31  Engine_Horsepower         25983 non-null   object        \n",
            " 32  Hydraulics                330133 non-null  object        \n",
            " 33  Pushblock                 25983 non-null   object        \n",
            " 34  Ripper                    106945 non-null  object        \n",
            " 35  Scarifier                 25994 non-null   object        \n",
            " 36  Tip_Control               25983 non-null   object        \n",
            " 37  Tire_Size                 97638 non-null   object        \n",
            " 38  Coupler                   220679 non-null  object        \n",
            " 39  Coupler_System            44974 non-null   object        \n",
            " 40  Grouser_Tracks            44875 non-null   object        \n",
            " 41  Hydraulics_Flow           44875 non-null   object        \n",
            " 42  Track_Type                102193 non-null  object        \n",
            " 43  Undercarriage_Pad_Width   102916 non-null  object        \n",
            " 44  Stick_Length              102261 non-null  object        \n",
            " 45  Thumb                     102332 non-null  object        \n",
            " 46  Pattern_Changer           102261 non-null  object        \n",
            " 47  Grouser_Type              102193 non-null  object        \n",
            " 48  Backhoe_Mounting          80712 non-null   object        \n",
            " 49  Blade_Type                81875 non-null   object        \n",
            " 50  Travel_Controls           81877 non-null   object        \n",
            " 51  Differential_Type         71564 non-null   object        \n",
            " 52  Steering_Controls         71522 non-null   object        \n",
            "dtypes: datetime64[ns](1), float64(3), int64(5), object(44)\n",
            "memory usage: 166.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx6OC_6BJcAN"
      },
      "source": [
        "### As saledate is datetime object type, We can make some feature engineering on it to extract the different attributes of It."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXuPqPIOt_K-"
      },
      "source": [
        "# lets sort the date first\r\n",
        "df.sort_values(by=['saledate'],\r\n",
        "               inplace=True,\r\n",
        "               ascending=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVz7CU0tGN5H"
      },
      "source": [
        "df[\"saleYear\"] = df.saledate.dt.year\r\n",
        "df[\"saleMonth\"] = df.saledate.dt.month\r\n",
        "df[\"saleDay\"] = df.saledate.dt.day\r\n",
        "df[\"saleDayofweek\"] = df.saledate.dt.dayofweek\r\n",
        "df[\"saleDayofyear\"] = df.saledate.dt.dayofyear\r\n",
        "\r\n",
        "# Drop original saledate as we do not need it\r\n",
        "df.drop(\"saledate\", axis=1, inplace=True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LVPg9dUKs_0"
      },
      "source": [
        "### Handling missing data\r\n",
        "we will start by recheck the miising data to drop columns with significant amount of missied data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYScxnTcsvwZ"
      },
      "source": [
        "## After some experimentation, I found that imputing the missing values with the median has good impact in the performance of model, so I will not drop them in this version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiJr7CVRGtBE",
        "outputId": "9eae6755-b297-416c-dd28-278b2bce2eeb"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SalesID                          0\n",
              "SalePrice                        0\n",
              "MachineID                        0\n",
              "ModelID                          0\n",
              "datasource                       0\n",
              "auctioneerID                 20136\n",
              "YearMade                         0\n",
              "MachineHoursCurrentMeter    265194\n",
              "UsageBand                   339028\n",
              "fiModelDesc                      0\n",
              "fiBaseModel                      0\n",
              "fiSecondaryDesc             140727\n",
              "fiModelSeries               354031\n",
              "fiModelDescriptor           337882\n",
              "ProductSize                 216605\n",
              "fiProductClassDesc               0\n",
              "state                            0\n",
              "ProductGroup                     0\n",
              "ProductGroupDesc                 0\n",
              "Drive_System                305611\n",
              "Enclosure                      334\n",
              "Forks                       214983\n",
              "Pad_Type                    331602\n",
              "Ride_Control                259970\n",
              "Stick                       331602\n",
              "Transmission                224691\n",
              "Turbocharged                331602\n",
              "Blade_Extension             386715\n",
              "Blade_Width                 386715\n",
              "Enclosure_Type              386715\n",
              "Engine_Horsepower           386715\n",
              "Hydraulics                   82565\n",
              "Pushblock                   386715\n",
              "Ripper                      305753\n",
              "Scarifier                   386704\n",
              "Tip_Control                 386715\n",
              "Tire_Size                   315060\n",
              "Coupler                     192019\n",
              "Coupler_System              367724\n",
              "Grouser_Tracks              367823\n",
              "Hydraulics_Flow             367823\n",
              "Track_Type                  310505\n",
              "Undercarriage_Pad_Width     309782\n",
              "Stick_Length                310437\n",
              "Thumb                       310366\n",
              "Pattern_Changer             310437\n",
              "Grouser_Type                310505\n",
              "Backhoe_Mounting            331986\n",
              "Blade_Type                  330823\n",
              "Travel_Controls             330821\n",
              "Differential_Type           341134\n",
              "Steering_Controls           341176\n",
              "saleYear                         0\n",
              "saleMonth                        0\n",
              "saleDay                          0\n",
              "saleDayofweek                    0\n",
              "saleDayofyear                    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nViBniqPOb27"
      },
      "source": [
        "# lets drop columns with more than 50 % missed data because this columns(Features) do not add any value\r\n",
        "# as well they may mislead the algorithm and to save the memory and processing time \r\n",
        "#limitPer = len(df) * .50\r\n",
        "#df = df.dropna(thresh=limitPer,axis=1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgxfRGnPOjqf"
      },
      "source": [
        "#df.info()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luwRcREIpdfR"
      },
      "source": [
        "# Filling the missed value by Median for numerical features and for Categorical non numerical Features after converting them into numerical types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzi1Jk6mpt4z"
      },
      "source": [
        "# Fill numeric rows with the median\r\n",
        "for label, content in df.items():\r\n",
        "    if pd.api.types.is_numeric_dtype(content):\r\n",
        "        if pd.isnull(content).sum():\r\n",
        "            # Fill missing numeric values with median since it's more robust than the mean\r\n",
        "            df[label] = content.fillna(content.median())"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHXoBFNaqW-1"
      },
      "source": [
        "# Turn categorical variables into numbers\r\n",
        "for label, content in df.items():\r\n",
        "    # Check columns which *aren't* numeric\r\n",
        "    if not pd.api.types.is_numeric_dtype(content):\r\n",
        "        # We add the +1 because pandas encodes missing categories as -1\r\n",
        "        df[label] = pd.Categorical(content).codes+1        "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5m440JdrCmt",
        "outputId": "de126c9e-1d48-4528-9e03-e3496876f6ce"
      },
      "source": [
        "# Check for Missing Values\r\n",
        "df.isna().sum()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SalesID                     0\n",
              "SalePrice                   0\n",
              "MachineID                   0\n",
              "ModelID                     0\n",
              "datasource                  0\n",
              "auctioneerID                0\n",
              "YearMade                    0\n",
              "MachineHoursCurrentMeter    0\n",
              "UsageBand                   0\n",
              "fiModelDesc                 0\n",
              "fiBaseModel                 0\n",
              "fiSecondaryDesc             0\n",
              "fiModelSeries               0\n",
              "fiModelDescriptor           0\n",
              "ProductSize                 0\n",
              "fiProductClassDesc          0\n",
              "state                       0\n",
              "ProductGroup                0\n",
              "ProductGroupDesc            0\n",
              "Drive_System                0\n",
              "Enclosure                   0\n",
              "Forks                       0\n",
              "Pad_Type                    0\n",
              "Ride_Control                0\n",
              "Stick                       0\n",
              "Transmission                0\n",
              "Turbocharged                0\n",
              "Blade_Extension             0\n",
              "Blade_Width                 0\n",
              "Enclosure_Type              0\n",
              "Engine_Horsepower           0\n",
              "Hydraulics                  0\n",
              "Pushblock                   0\n",
              "Ripper                      0\n",
              "Scarifier                   0\n",
              "Tip_Control                 0\n",
              "Tire_Size                   0\n",
              "Coupler                     0\n",
              "Coupler_System              0\n",
              "Grouser_Tracks              0\n",
              "Hydraulics_Flow             0\n",
              "Track_Type                  0\n",
              "Undercarriage_Pad_Width     0\n",
              "Stick_Length                0\n",
              "Thumb                       0\n",
              "Pattern_Changer             0\n",
              "Grouser_Type                0\n",
              "Backhoe_Mounting            0\n",
              "Blade_Type                  0\n",
              "Travel_Controls             0\n",
              "Differential_Type           0\n",
              "Steering_Controls           0\n",
              "saleYear                    0\n",
              "saleMonth                   0\n",
              "saleDay                     0\n",
              "saleDayofweek               0\n",
              "saleDayofyear               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2n5ojdZu-AN"
      },
      "source": [
        "### It turns out that There is no missing values now, all data is numerical form,  So lets Go to Modeling stage to build up a predictive model for that regression problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUQtM2MEviim"
      },
      "source": [
        "# <font color='red'>  Modeling </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp3ZQPCVttEF",
        "outputId": "5600b45d-fcd8-4eec-ea53-dff4bbf087ff"
      },
      "source": [
        "# Splitting data ito x and y and into train and valid datasets\r\n",
        "df_val = df[df.saleYear == 2012]\r\n",
        "df_train = df[df.saleYear != 2012]\r\n",
        "X_train, y_train = df_train.drop(\"SalePrice\", axis=1), df_train.SalePrice\r\n",
        "X_valid, y_valid = df_val.drop(\"SalePrice\", axis=1), df_val.SalePrice\r\n",
        "\r\n",
        "np.random.seed(42) # random seed for reproduciblity of the result.\r\n",
        "\r\n",
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape\r\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((401125, 56), (401125,), (11573, 56), (11573,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlVck3OmxH1l"
      },
      "source": [
        "### According to the Kaggle data page, the validation set and test set are split according to dates.\r\n",
        "* Training = all samples up until 2011\r\n",
        "* Valid = all samples form January 1, 2012 - April 30, 2012\r\n",
        "* Test = all samples from May 1, 2012 - November 2012"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTgoWZz-wUFH"
      },
      "source": [
        "#After experimentation, I will use the RandomForesst Regressor which gives me a high performance in this dataset\r\n",
        "RF = RandomForestRegressor(n_estimators=100, max_samples=40000, n_jobs=-1, random_state=42,)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwMuEvb5z7H-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88274bb-cbe9-4b1a-a234-fcdc97fd3547"
      },
      "source": [
        " RF.fit(X_train, y_train)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=40000, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
              "                      random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLwBcKTjwBTh"
      },
      "source": [
        "## Model Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E4oaX-hwARw",
        "outputId": "56988c68-30e3-4ab9-fd4b-f0cd6401d468"
      },
      "source": [
        "#lets score on the validation set to see our performance regarding to the leaderbooard on kaggle\r\n",
        "RF.score(X_valid, y_valid)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8621335479880188"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akJ94AZNwmlr"
      },
      "source": [
        "### Score by default use the R2 metric, but the competition choosed RMSLE\r\n",
        "* Root Mean Square Log Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsKoo1mxwcge",
        "outputId": "0ddf8e5a-3835-474e-ce2f-12889aa11e4f"
      },
      "source": [
        "# there is no direct method to get RMSLE, so we need to find MSLE first\r\n",
        "y_preds = RF.predict(X_valid)\r\n",
        "RMSLE = np.sqrt(mean_squared_log_error(y_valid, y_preds))\r\n",
        "RMSLE"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2666847543913338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1L1bL6xxkwC"
      },
      "source": [
        "## Now, lets score on the test set to see our final performance\r\n",
        "* we will use the same preprocessing steps that used on the training and validation sets, otherwise, we can not used our trained model!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7Ho7vvlxgQO"
      },
      "source": [
        "x_test = pd.read_csv(\"/content/Test.csv\",\r\n",
        "                 low_memory=False,\r\n",
        "                 parse_dates=[\"saledate\"])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHoLNExJzNb9"
      },
      "source": [
        "#sort by saledate\r\n",
        "df_test.sort_values(by=['saledate'],\r\n",
        "               inplace=True,\r\n",
        "               ascending=True)\r\n",
        "\r\n",
        "#feature engineering on Date\r\n",
        "X_test[\"saleYear\"] = X_test.saledate.dt.year\r\n",
        "X_test[\"saleMonth\"] = X_test.saledate.dt.month\r\n",
        "X_test[\"saleDay\"] = X_test.saledate.dt.day\r\n",
        "X_test[\"saleDayofweek\"] = X_test.saledate.dt.dayofweek\r\n",
        "X_test[\"saleDayofyear\"] = X_test.saledate.dt.dayofyear\r\n",
        "\r\n",
        "# Drop original saledate as we do not need it\r\n",
        "X_test.drop(\"saledate\", axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YhopXXFztDK"
      },
      "source": [
        "# Fill numeric rows with the median\r\n",
        "for label, content in X_test.items():\r\n",
        "    if pd.api.types.is_numeric_dtype(content):\r\n",
        "        if pd.isnull(content).sum():\r\n",
        "            # Fill missing numeric values with median since it's more robust than the mean\r\n",
        "            X_test[label] = content.fillna(content.median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTaOi63W6D1g"
      },
      "source": [
        "# Turn categorical variables into numbers\r\n",
        "for label, content in X_test.items():\r\n",
        "    # Check columns which *aren't* numeric\r\n",
        "    if not pd.api.types.is_numeric_dtype(content):\r\n",
        "        # We add the +1 because pandas encodes missing categories as -1\r\n",
        "        X_test[label] = pd.Categorical(content).codes+1        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ge8rBAi6Guz"
      },
      "source": [
        "#predicting the SalePrice\r\n",
        "y_preds = RF.predict(X_test)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFNm9tql6iTj"
      },
      "source": [
        "### Since we do not have the True Price and we can not submit  our solution on Kaggle, we can not calculate the final performance of the model (RMSLE )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-CcsK0Y6tz4"
      },
      "source": [
        " #rmsle = np.sqrt(mean_squared_log_error(y_test, y_preds))\r\n",
        " #rmsle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtIYsf-i7LZF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}